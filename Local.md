# Local Deployment
Use the "AirQualityStream_Local.py" Python Script.


## 1) Install Dependencies

![image](https://github.com/Timilla/api-kafka-spark-pipeline/assets/48120404/c4c15196-c00b-4ba3-bdf6-d1491acfa242)

## 2) Start Zookeeper

![image](https://github.com/Timilla/api-kafka-spark-pipeline/assets/48120404/1515034c-2bba-4179-ab14-0e8641694dec)

## 3) Start Kafka Broker

![image](https://github.com/Timilla/api-kafka-spark-pipeline/assets/48120404/077877d8-5981-4daf-b611-5005c8384274)

## 4) Create a Kafka Topic

![image](https://github.com/Timilla/api-kafka-spark-pipeline/assets/48120404/edbf0fff-f33e-447b-b096-3e05b120c1ff)

## 5) Run the Pipeline
- Add arguments to the Python script :

![image](https://github.com/Timilla/api-kafka-spark-pipeline/assets/48120404/a7e805ec-c5c7-4aa2-9317-5fbf6975ac20)

- Output AirQuality informations to the console :

![image](https://github.com/Timilla/api-kafka-spark-pipeline/assets/48120404/cdc385f6-8044-4fdc-be4b-d6c87f8d7bfb)

- Store AirQuality informations into a .csv file for each time epoch (2 time steps configuration here) :

![image](https://github.com/Timilla/api-kafka-spark-pipeline/assets/48120404/45db89a0-955b-40bd-aa00-b3785aebc9c0)

![image](https://github.com/Timilla/api-kafka-spark-pipeline/assets/48120404/8a8e82d4-48c3-412e-93c9-465da2dd0d1b)

![image](https://github.com/Timilla/api-kafka-spark-pipeline/assets/48120404/fdf985fa-2a23-4e10-998a-2c8d48a7b999)


